{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3cf5c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Librerias implementadas\n",
    "import scipy.io\n",
    "import copy\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import pickle\n",
    "import scipy.io as sio\n",
    "from sklearn import svm\n",
    "from sklearn import linear_model\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn import tree\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import confusion_matrix, precision_score, f1_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import median_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from IPython.display import Image\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0b52463",
   "metadata": {},
   "outputs": [],
   "source": [
    "#....\n",
    "def cargardatos(datos_tesis):\n",
    "\n",
    "    datos=pd.read_csv(datos_tesis, sep=',')\n",
    "    datos=datos.drop(['LOGICA COMPUTACIONAL','PROGRAMACION I','PROGRAMACION II','PROGRAMACION III'], axis=1)\n",
    "    \n",
    "\n",
    "    X = datos[['LECTURA CRITICA','MATEMATICA','INGLES','SOCIALES Y CIUDADANIA','CIENCIAS NATURALES']]\n",
    "    Y = datos['PROMEDIO PROGRAMACIONES']\n",
    "    X = X.to_numpy()\n",
    "    Y = Y.to_numpy()\n",
    "    return(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5384465",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y=cargardatos('Datos-Tesis.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1e246c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definir la cantidad de datos que se asignarán al conjunto de entrenamiento y de prueba\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "#print(X_train, X_test, y_train, y_test)\n",
    "#Definir elementos para evaluación de los modelos\n",
    "\n",
    "kf = KFold(n_splits=5)\n",
    "#inicializando el modelo.\n",
    "LR=LinearRegression()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3845a5b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best  r2: 0.228\n",
      "Best Config: {'copy_X': False, 'fit_intercept': True, 'normalize': True}\n",
      ">6.019 with: {'copy_X': False, 'fit_intercept': False, 'normalize': False}\n",
      ">6.019 with: {'copy_X': False, 'fit_intercept': False, 'normalize': True}\n",
      ">0.228 with: {'copy_X': False, 'fit_intercept': True, 'normalize': False}\n",
      ">0.228 with: {'copy_X': False, 'fit_intercept': True, 'normalize': True}\n",
      ">6.019 with: {'copy_X': True, 'fit_intercept': False, 'normalize': False}\n",
      ">6.019 with: {'copy_X': True, 'fit_intercept': False, 'normalize': True}\n",
      ">0.228 with: {'copy_X': True, 'fit_intercept': True, 'normalize': False}\n",
      ">0.228 with: {'copy_X': True, 'fit_intercept': True, 'normalize': True}\n"
     ]
    }
   ],
   "source": [
    "# define grid\n",
    "grid1 = dict()\n",
    "grid1['fit_intercept'] = [False,True]\n",
    "grid1['normalize']=[False,True]\n",
    "grid1['copy_X']=[False,True]\n",
    "\n",
    "sco=['neg_mean_squared_error','neg_median_absolute_error','r2']\n",
    "\n",
    "\n",
    "# define search\n",
    "\n",
    "search1 = GridSearchCV(LR, grid1, scoring='r2', cv=kf, n_jobs=-1)\n",
    "# perform the search\n",
    "results = search1.fit(X_train, Y_train)\n",
    "pos=(-1)* results.best_score_\n",
    "# summarize best\n",
    "print('Best  r2: %.3f' % pos)\n",
    "print('Best Config: %s' % results.best_params_)\n",
    "# summarize all\n",
    "means = results.cv_results_['mean_test_score']\n",
    "params = results.cv_results_['params']\n",
    "for mean, param in zip(means, params):\n",
    "    print(\">%.3f with: %r\" % (mean * -1, param))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1aa26a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best mean_squared_error: 0.072\n",
      "Best Config: {'copy_X': False, 'fit_intercept': True, 'normalize': True}\n",
      ">0.304 with: {'copy_X': False, 'fit_intercept': False, 'normalize': False}\n",
      ">0.304 with: {'copy_X': False, 'fit_intercept': False, 'normalize': True}\n",
      ">0.072 with: {'copy_X': False, 'fit_intercept': True, 'normalize': False}\n",
      ">0.072 with: {'copy_X': False, 'fit_intercept': True, 'normalize': True}\n",
      ">0.304 with: {'copy_X': True, 'fit_intercept': False, 'normalize': False}\n",
      ">0.304 with: {'copy_X': True, 'fit_intercept': False, 'normalize': True}\n",
      ">0.072 with: {'copy_X': True, 'fit_intercept': True, 'normalize': False}\n",
      ">0.072 with: {'copy_X': True, 'fit_intercept': True, 'normalize': True}\n"
     ]
    }
   ],
   "source": [
    "# define grid\n",
    "grid1 = dict()\n",
    "grid1['fit_intercept'] = [False,True]\n",
    "grid1['normalize']=[False,True]\n",
    "grid1['copy_X']=[False,True]\n",
    "\n",
    "sco=['neg_mean_squared_error','neg_median_absolute_error','r2']\n",
    "\n",
    "# define search\n",
    "\n",
    "search1 = GridSearchCV(LR, grid1, scoring='neg_mean_squared_error', cv=kf, n_jobs=-1)\n",
    "# perform the search\n",
    "results = search1.fit(X_train, Y_train)\n",
    "pos=(-1)* results.best_score_\n",
    "# summarize best\n",
    "print('Best mean_squared_error: %.3f' % pos)\n",
    "print('Best Config: %s' % results.best_params_)\n",
    "# summarize all\n",
    "means = results.cv_results_['mean_test_score']\n",
    "params = results.cv_results_['params']\n",
    "for mean, param in zip(means, params):\n",
    "    print(\">%.3f with: %r\" % (mean * -1, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280c9ab3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "15a4c977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best  neg_root_mean_squared_error: 0.255\n",
      "Best Config: {'copy_X': False, 'fit_intercept': True, 'normalize': True}\n",
      ">0.516 with: {'copy_X': False, 'fit_intercept': False, 'normalize': False}\n",
      ">0.516 with: {'copy_X': False, 'fit_intercept': False, 'normalize': True}\n",
      ">0.255 with: {'copy_X': False, 'fit_intercept': True, 'normalize': False}\n",
      ">0.255 with: {'copy_X': False, 'fit_intercept': True, 'normalize': True}\n",
      ">0.516 with: {'copy_X': True, 'fit_intercept': False, 'normalize': False}\n",
      ">0.516 with: {'copy_X': True, 'fit_intercept': False, 'normalize': True}\n",
      ">0.255 with: {'copy_X': True, 'fit_intercept': True, 'normalize': False}\n",
      ">0.255 with: {'copy_X': True, 'fit_intercept': True, 'normalize': True}\n"
     ]
    }
   ],
   "source": [
    "# define grid\n",
    "grid1 = dict()\n",
    "grid1['fit_intercept'] = [False,True]\n",
    "grid1['normalize']=[False,True]\n",
    "grid1['copy_X']=[False,True]\n",
    "\n",
    "sco=['neg_mean_squared_error','neg_median_absolute_error','r2']\n",
    "\n",
    "search1 = GridSearchCV(LR, grid1, scoring='neg_root_mean_squared_error', cv=kf, n_jobs=-1)\n",
    "# perform the search\n",
    "results = search1.fit(X_train, Y_train)\n",
    "pos=(-1)* results.best_score_\n",
    "# summarize best\n",
    "print('Best  neg_root_mean_squared_error: %.3f' % pos)\n",
    "print('Best Config: %s' % results.best_params_)\n",
    "# summarize all\n",
    "means = results.cv_results_['mean_test_score']\n",
    "params = results.cv_results_['params']\n",
    "for mean, param in zip(means, params):\n",
    "    print(\">%.3f with: %r\" % (mean * -1, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a8b1a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
